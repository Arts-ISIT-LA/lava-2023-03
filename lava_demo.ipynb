{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook, you will need to first set up your Python environment to work with spaCy. You can do this by either running this folder within a VS Code Dev Container (this repo has the necessary configuration files; see [VS Code documentation](https://code.visualstudio.com/docs/devcontainers/containers) for setup instructions) or by running the following commands within a Python/Jupyter environment:\n",
    "\n",
    "```bash\n",
    "pip install la-nlp\n",
    "python -m spacy download en_core_web_lg\n",
    "pip install pandas\n",
    "```\n",
    "\n",
    "The first command will install spaCy into our environment, while the second installs the language model that we will be using, in this case the `en_core_web_sm` model, a minimal model for processing English-language text. However, spaCy provides a number of other models with support for other languages as well. For a list of available language models, please see [spaCy's website](https://spacy.io/usage/models).\n",
    "\n",
    "Once the above dependencies are installed, you should be able to run all code contained within this notebook.\n",
    "\n",
    "Helpful links:\n",
    "\n",
    "- [LA NLP source code](https://github.com/Arts-ISIT-LA/la-nlp)\n",
    "- [LA NLP documentation](https://github.com/Arts-ISIT-LA/la-nlp/blob/main/docs/docs.md)\n",
    "- [spaCy documentation](https://spacy.io/usage)\n",
    "- [VADER Sentiment Analysis documentation](https://github.com/cjhutto/vaderSentiment#python-demo-and-code-examples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy demo\n",
    "\n",
    "## Setup\n",
    "\n",
    "Once installed, spaCy requires very little code to get working. First, we need to import the package itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once spaCy is imported, we also need to load the language model we will be using, in this case the `en_core_web_lg` model that we downloaded earlier. By convention, we load this model into a Python object named `nlp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage\n",
    "\n",
    "Now that we have loaded the model into our `nlp` variable, we are ready to run the model over some text. To do so, all we have to do is run `nlp()` on the text that we want to analyze. This will return a new object that we will call `doc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello world!\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy has now run its [processing pipeline](https://spacy.io/usage/processing-pipelines) over the text that we fed into the model. The new `doc` object created by this process now contains a number of features and attributes that we do not get with a normal string.\n",
    "\n",
    "We can easily see the difference between `doc` and `text` by looking at their lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 12\n",
      "Length of doc:  3\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of text: {len(text)}')\n",
    "print(f'Length of doc:  {len(doc)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being a standard Python string object, our `text` is little more than an array of characters. When we check its length, Python gives us the number of characters.\n",
    "\n",
    "The `doc`, on the other hand, has been 'tokenized' and split into individual tokens. We can see how spaCy tokenized the text by looping through the doc and printing each token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Hello\n",
      "1 world\n",
      "2 !\n"
     ]
    }
   ],
   "source": [
    "for i, token in enumerate(doc):\n",
    "    print(i, token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy also takes care of tagging each word with its part of speech. To see these tags, we can again loop through the tokens and print their parts of speech. These tags come from the [Universal Dependencies](https://universaldependencies.org/) project. A list of tags and their meanings can be viewed on [this page](https://universaldependencies.org/u/pos/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello - INTJ\n",
      "world - NOUN\n",
      "! - PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, '-', token.pos_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the underscore in `token.pos_`. Internally, spaCy uses pure numbers for part-of-speech tagging. Without the underscore, we will get the internal integer value of the tag, while the underscore gives us the string representation of said tag."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy data types\n",
    "\n",
    "spaCy utilizes three main data types:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Doc`\n",
    "\n",
    "A `Doc` is a complete text that has been processed by the spaCy pipeline. A `Doc` consists of a sequence of `Token` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'> - Vancouver is a very rainy city.\n"
     ]
    }
   ],
   "source": [
    "text = \"Vancouver is a very rainy city.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "print(type(doc), '-', doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Token`\n",
    "\n",
    "A `Token` is an individual token in a `Doc`, usually a word, punctuation, symbol, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.token.Token'> - Vancouver\n"
     ]
    }
   ],
   "source": [
    "token = doc[0]\n",
    "\n",
    "print(type(token), '-', token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Span`\n",
    "\n",
    "A `Span` is a slice of a `Doc`. This could be either a sentence within a larger `Doc` or just a multi-token phrase. In other words, a `Span` is any sequence of `Token` objects that is not a `Doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.span.Span'> - rainy city\n"
     ]
    }
   ],
   "source": [
    "span = doc[4:6]\n",
    "\n",
    "print(type(span), '-', span)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency parsing\n",
    "\n",
    "One component of the spaCy processing pipeline is the dependency parser. Dependency parsing is the process of analyzing the relationships between words in a text to understand which words are 'dependent' on others. This is done by creating a set of one-way relationships where each word has a single 'head' and can have none or multiple 'children'. spaCy lets us easily visualize these relationships using its [displaCy](https://spacy.io/universe/project/displacy) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a689c58b7f8448928e195c77e7de6cfe-0\" class=\"displacy\" width=\"750\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">work</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">UBC</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a689c58b7f8448928e195c77e7de6cfe-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a689c58b7f8448928e195c77e7de6cfe-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a689c58b7f8448928e195c77e7de6cfe-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a689c58b7f8448928e195c77e7de6cfe-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a689c58b7f8448928e195c77e7de6cfe-0-2\" stroke-width=\"2px\" d=\"M420,89.5 C420,2.0 575.0,2.0 575.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a689c58b7f8448928e195c77e7de6cfe-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,91.5 L583.0,79.5 567.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"I work at UBC\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "spacy.displacy.render(doc, style='dep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each arrow represents a relationship between two words, starting from the head and pointing towards the child."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using spaCy, we can navigate a text's dependency relationships programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I - work - []\n",
      "work - work - [I, at]\n",
      "at - work - [UBC]\n",
      "UBC - at - []\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, '-', token.head, '-', [child for child in token.children])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to dive deeper into what dependency parsing is and how it works, see [this lecture from Stanford University](https://www.youtube.com/watch?v=PVShkZgXznc)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VADER demo\n",
    "\n",
    "Using VADER (Valence Aware Dictionary and sEntiment Reasoner), we can also easily calculate sentiment scores for any text. Note that VADER is entirely separate from spaCy and the two are not related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.494, 'pos': 0.506, 'compound': 0.6249}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "text = \"Vancouver is a great city.\"\n",
    "\n",
    "analyzer.polarity_scores(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LA NLP / ABSA demo\n",
    "\n",
    "Using spaCy, we are developing our own NLP package for learning analytics called LA NLP. This should be installed in your environment if you followed the instructions at the top of this notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, we have written one pipeline for conducting aspect-based sentiment analysis (ABSA) in Python. This pipeline uses the spaCy dependency parser to find which section of a text is related to a given token, then uses VADER to compute sentiment on that section.\n",
    "\n",
    "To use it, we first need to import the pipeline from the LA NLP package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from la_nlp.pipes import aspect_sentiment as absa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need some text to analyze and a set of aspects with keywords that we would like to measure sentiment for within the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The pizza and pasta were good, but the waiter was rude. Will come back just for the food though.\"\n",
    "\n",
    "aspects = {\n",
    "    'food': ['food', 'pizza', 'pasta'],\n",
    "    'service': ['service', 'waiter'],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now feed both the text and aspects into the `absa.make_doc()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = absa.make_doc(text, aspects)\n",
    "\n",
    "type(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the object that is created here is merely another spaCy `Doc` object. This object has all of the same features and attributes explored in the spaCy demo above. However, it also has additional attributes that we have created specifically for conducting ABSA. spaCy allows us to create these attributes by assigning special underscore `_` extensions on each of the main data types explored earlier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, `doc` now has a `doc._.keywords` attribute which is a list of all keywords found within the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pizza, pasta, waiter, food]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.keywords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each keyword is a `Token` object with its own custom attributes in turn. We can put all of these attributes together in a Pandas dataframe for a quick overview of what our ABSA code is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>aspect</th>\n",
       "      <th>parent_span</th>\n",
       "      <th>parent_span_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pizza</td>\n",
       "      <td>food</td>\n",
       "      <td>The pizza and pasta were good,</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pasta</td>\n",
       "      <td>food</td>\n",
       "      <td>The pizza and pasta were good,</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>waiter</td>\n",
       "      <td>service</td>\n",
       "      <td>the waiter was rude.</td>\n",
       "      <td>-0.4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food</td>\n",
       "      <td>food</td>\n",
       "      <td>Will come back just for the food though.</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword   aspect                               parent_span  \\\n",
       "0  pizza   food     The pizza and pasta were good,             \n",
       "1  pasta   food     The pizza and pasta were good,             \n",
       "2  waiter  service  the waiter was rude.                       \n",
       "3  food    food     Will come back just for the food though.   \n",
       "\n",
       "   parent_span_sentiment  \n",
       "0  0.4404                 \n",
       "1  0.4404                 \n",
       "2 -0.4588                 \n",
       "3  0.0000                 "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "\n",
    "def summarize_sentiments(doc):\n",
    "    data = []\n",
    "\n",
    "    for keyword in doc._.keywords:\n",
    "        new_row = {\n",
    "            'keyword': keyword.text,\n",
    "            'aspect': keyword._.aspect,\n",
    "            'parent_span': keyword._.parent_span.text,\n",
    "            'parent_span_sentiment': keyword._.parent_span._.sentiment\n",
    "        }\n",
    "        data.append(new_row)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "summarize_sentiments(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see a quick summary of the sentiment expressed towards each aspect by running `Doc._.aspect_sentiments`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food': 0.2936, 'service': -0.4588}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.aspect_sentiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens if we have a customer review expressing the opposite opinion (good service, but bad food)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food': -0.8271, 'service': 0.6361}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"We absolutely loved our waiter. However, the pasta was unfortunately disappointing, much worse than we expected.\"\n",
    "\n",
    "doc = absa.make_doc(text, aspects)\n",
    "\n",
    "doc._.aspect_sentiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can see a quick snapshot of this review's sentiments by putting the data into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>aspect</th>\n",
       "      <th>parent_span</th>\n",
       "      <th>parent_span_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waiter</td>\n",
       "      <td>service</td>\n",
       "      <td>We absolutely loved our waiter.</td>\n",
       "      <td>0.6361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pasta</td>\n",
       "      <td>food</td>\n",
       "      <td>However, the pasta was unfortunately disappointing, much worse than we expected.</td>\n",
       "      <td>-0.8271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword   aspect  \\\n",
       "0  waiter  service   \n",
       "1  pasta   food      \n",
       "\n",
       "                                                                        parent_span  \\\n",
       "0  We absolutely loved our waiter.                                                    \n",
       "1  However, the pasta was unfortunately disappointing, much worse than we expected.   \n",
       "\n",
       "   parent_span_sentiment  \n",
       "0  0.6361                 \n",
       "1 -0.8271                 "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_sentiments(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this package takes aspects that are passed by the user at runtime, it is flexible for any type of text, so long as you know what aspects you want to be measuring within the text. There are also some aspects specifically for analyzing course reviews that are built into the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'course': 0.6249,\n",
       " 'content': None,\n",
       " 'assignments': None,\n",
       " 'tests': None,\n",
       " 'instructor': -0.4588}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This was a great class. However, the professor was rude and disrespectful toward students.\"\n",
    "\n",
    "doc = absa.make_doc(text)\n",
    "\n",
    "doc._.aspect_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>aspect</th>\n",
       "      <th>parent_span</th>\n",
       "      <th>parent_span_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class</td>\n",
       "      <td>course</td>\n",
       "      <td>This was a great class.</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>professor</td>\n",
       "      <td>instructor</td>\n",
       "      <td>However, the professor was rude and disrespectful toward students.</td>\n",
       "      <td>-0.4588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword      aspect  \\\n",
       "0  class      course       \n",
       "1  professor  instructor   \n",
       "\n",
       "                                                          parent_span  \\\n",
       "0  This was a great class.                                              \n",
       "1  However, the professor was rude and disrespectful toward students.   \n",
       "\n",
       "   parent_span_sentiment  \n",
       "0  0.6249                 \n",
       "1 -0.4588                 "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_sentiments(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
