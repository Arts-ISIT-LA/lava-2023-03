{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy demo\n",
    "\n",
    "To run this notebook, you will need to first set up your Python environment to work with spaCy. You can do this by either running a VS Code Dev Container with Docker (this repo has the necessary configuration files; see [VS Code documentation](https://code.visualstudio.com/docs/devcontainers/containers) for setup instructions) or by running the following commands within a Python/Jupyter environment:\n",
    "\n",
    "```bash\n",
    "pip install spacy\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "The first command will install spaCy into our environment, while the second installs the language model that we will be using, in this case the `en_core_web_sm` model, a minimal model for processing English-language text. However, spaCy provides a number of other models with support for other languages as well. For a list of available language models, please see [spaCy's website](https://spacy.io/usage/models).\n",
    "\n",
    "Once the above dependencies are installed, you should be able to run all code contained within this notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Once installed, spaCy requires very little code to get working. First, we need to import the package itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once spaCy is imported, we also need to load the language model we will be using, in this case the `en_core_web_sm` model that we downloaded earlier. By convention, we load this model into a Python object named `nlp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage\n",
    "\n",
    "Now that we have loaded the model into our `nlp` variable, we are ready to run the model over some text. To do so, all we have to do is run `nlp()` on the text that we want to analyze. This will return a new object that we will call `doc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello world!\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy has now run its [processing pipeline](https://spacy.io/usage/processing-pipelines) over the text that we fed into the model. The new `doc` object created by this process now contains a number of features and attributes that we do not get with a normal string.\n",
    "\n",
    "We can easily see the difference between `doc` and `text` by looking at their lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 12\n",
      "Length of doc:  3\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of text: {len(text)}')\n",
    "print(f'Length of doc:  {len(doc)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being a standard Python string object, our `text` is little more than an array of characters. When we check its length, Python gives us the number of characters.\n",
    "\n",
    "The `doc`, on the other hand, has been 'tokenized' and split into individual tokens. We can see how spaCy tokenized the text by looping through the doc and printing each token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "world\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy also takes care of tagging each word with its part of speech. To see these tags, we can again loop through the tokens and print their parts of speech. These tags come from the [Universal Dependencies](https://universaldependencies.org/) project. A list of tags and their meanings can be viewed on [this page](https://universaldependencies.org/u/pos/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello - INTJ\n",
      "world - NOUN\n",
      "! - PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, '-', token.pos_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the underscore in `token.pos_`. Internally, spaCy uses pure numbers for part-of-speech tagging. Without the underscore, we will get the internal integer value of the tag, while the underscore gives us the string representation of said tag."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency parsing\n",
    "\n",
    "One component of the spaCy processing pipeline is the dependency parser. Dependency parsing is the process of analyzing the relationships between words in a text to understand which words are 'dependent' on others. This is done by creating a set of one-way relationships where each word has a single 'head' and can have none or multiple 'children'. spaCy lets us easily visualize these relationships using its [displaCy](https://spacy.io/universe/project/displacy) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9c0bab93e082420bb00074e5090941ff-0\" class=\"displacy\" width=\"750\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">work</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">UBC.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c0bab93e082420bb00074e5090941ff-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c0bab93e082420bb00074e5090941ff-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c0bab93e082420bb00074e5090941ff-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c0bab93e082420bb00074e5090941ff-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c0bab93e082420bb00074e5090941ff-0-2\" stroke-width=\"2px\" d=\"M420,89.5 C420,2.0 575.0,2.0 575.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c0bab93e082420bb00074e5090941ff-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,91.5 L583.0,79.5 567.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"I work at UBC.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "spacy.displacy.render(doc, style='dep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each arrow represents a relationship between two words, starting from the head and pointing towards the child."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using spaCy, we can navigate a text's dependency relationships programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I - work - []\n",
      "work - work - [I, at, .]\n",
      "at - work - [UBC]\n",
      "UBC - at - []\n",
      ". - work - []\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, '-', token.head, '-', [child for child in token.children])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to dive deeper into what dependency parsing is and how it works, see [this lecture from Stanford University](https://www.youtube.com/watch?v=PVShkZgXznc)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
